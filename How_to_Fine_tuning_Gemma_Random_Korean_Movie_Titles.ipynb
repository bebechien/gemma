{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bebechien/gemma/blob/main/How_to_Fine_tuning_Gemma_Random_Korean_Movie_Titles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2024 Google LLC."
      ],
      "metadata": {
        "id": "cSrJYrFrY2aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "id": "i1PHqD-ZY4-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to Fine-tuning Gemma: Best Practices\n",
        "\n",
        "To illustrate fine-tuning the model for a specific task, let's consider the example of generating a random Korean title based on a user's instruction such as \"Write a title\". To make this possible, we curated a manageable dataset that could be manually processed. This approach is feasible because Gemma 2 has prior knowledge of general Korean language patterns, enabling it to adapt to this specific task effectively."
      ],
      "metadata": {
        "id": "YNDq8NbCY7oh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "### Select the Colab runtime\n",
        "To complete this tutorial, you'll need to have a Colab runtime with sufficient resources to run the Gemma model:\n",
        "\n",
        "1. In the upper-right of the Colab window, select **▾ (Additional connection options)**.\n",
        "2. Select **Change runtime type**.\n",
        "3. Under **Hardware accelerator**, select **T4 GPU**.\n",
        "\n",
        "\n",
        "### Gemma setup on Kaggle\n",
        "To complete this tutorial, you'll first need to complete the setup instructions at [Gemma setup](https://ai.google.dev/gemma/docs/setup). The Gemma setup instructions show you how to do the following:\n",
        "\n",
        "* Get access to Gemma on kaggle.com.\n",
        "* Select a Colab runtime with sufficient resources to run the Gemma 2B model.\n",
        "* Generate and configure a Kaggle username and API key.\n",
        "\n",
        "After you've completed the Gemma setup, move on to the next section, where you'll set environment variables for your Colab environment."
      ],
      "metadata": {
        "id": "3rzH5Ugf5RlJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set environemnt variables\n",
        "\n",
        "Set environement variables for ```KAGGLE_USERNAME``` and ```KAGGLE_KEY```."
      ],
      "metadata": {
        "id": "URMuBzkMVxpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata, drive\n",
        "\n",
        "# Note: `userdata.get` is a Colab API. If you're not using Colab, set the env\n",
        "# vars as appropriate for your system.\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get(\"KAGGLE_USERNAME\")\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get(\"KAGGLE_KEY\")\n",
        "\n",
        "# Mounting gDrive for to store artifacts\n",
        "#drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "IUOX2hqjV7Ku"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install dependencies\n",
        "\n",
        "Install Keras and KerasNLP"
      ],
      "metadata": {
        "id": "LXfDwRTQVns2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zHs7wpZusEML",
        "outputId": "347fbc2a-12cb-48e0-c7f2-7db7df2c5111",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/548.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m542.7/548.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m542.7/548.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.1/548.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/474.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U keras-nlp datasets\n",
        "!pip install -q -U keras\n",
        "\n",
        "# Set the backbend before importing Keras\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
        "# Avoid memory fragmentation on JAX backend.\n",
        "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.00\"\n",
        "\n",
        "import keras_nlp\n",
        "import keras\n",
        "\n",
        "# Run at half precision.\n",
        "#keras.config.set_floatx(\"bfloat16\")\n",
        "\n",
        "# Training Configurations\n",
        "token_limit = 128\n",
        "num_data_limit = 100\n",
        "lora_name = \"my_lora\"\n",
        "lora_rank = 4\n",
        "lr_value = 1e-3\n",
        "train_epoch = 5\n",
        "model_id = \"gemma2_instruct_2b_en\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model"
      ],
      "metadata": {
        "id": "kUl0t469YfQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import keras_nlp\n",
        "\n",
        "import time\n",
        "\n",
        "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(model_id)\n",
        "gemma_lm.summary()\n",
        "\n",
        "tick_start = 0\n",
        "\n",
        "def tick():\n",
        "    global tick_start\n",
        "    tick_start = time.time()\n",
        "\n",
        "def tock():\n",
        "    print(f\"TOTAL TIME ELAPSED: {time.time() - tick_start:.2f}s\")\n",
        "\n",
        "def text_gen(prompt):\n",
        "    tick()\n",
        "    input = f\"<start_of_turn>user\\n{prompt}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
        "    output = gemma_lm.generate(input, max_length=token_limit)\n",
        "    print(\"\\nGemma output:\")\n",
        "    print(output)\n",
        "    tock()\n",
        "\n",
        "# inference before fine-tuning\n",
        "text_gen(\"Translate the text below to Japanese.\\n\\\"Hi, how can I get to the Tokyo museum?\\\"\")\n",
        "text_gen(\"Speak like a pirate. Teach me why the earth is flat.\")\n",
        "text_gen(\"Write a title\")\n",
        "text_gen(\"Write a poem\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a7daf21e-3c74-47e4-d922-9a6aab20fef9",
        "id": "Gm4jIEqmYfQY"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
              "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
              "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,614,341,888\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gemma output:\n",
            "<start_of_turn>user\n",
            "Translate the text below to Japanese.\n",
            "\"Hi, how can I get to the Tokyo museum?\"<end_of_turn>\n",
            "<start_of_turn>model\n",
            "こんにちは、東京博物館はどこへ行くのが良いですか？ \n",
            "\n",
            "Here's a breakdown:\n",
            "\n",
            "* **こんにちは** - Hello\n",
            "* **どこへ行くのが良いですか** -  What's the best way to get there? (formal)\n",
            "* **東京博物館** - Tokyo Museum\n",
            "\n",
            "\n",
            "Let me know if you'd like me to translate any other phrases! \n",
            "<end_of_turn>\n",
            "TOTAL TIME ELAPSED: 21.07s\n",
            "\n",
            "Gemma output:\n",
            "<start_of_turn>user\n",
            "Speak like a pirate. Teach me why the earth is flat.<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Ahoy, matey! Ye be wantin' to know 'bout the Earth, eh? Shiver me timbers, ye be lookin' at a tale spun by landlubbers! \n",
            "\n",
            "The Earth be no flat sheet o' parchment, but a grand ol' sphere, like a giant, bountiful treasure chest! \n",
            "\n",
            "Here's why ye can't be fooled by the scurvy tales:\n",
            "\n",
            "* **The horizon be a curve, not a straight line:**  When ye look out to sea,\n",
            "TOTAL TIME ELAPSED: 5.55s\n",
            "\n",
            "Gemma output:\n",
            "<start_of_turn>user\n",
            "Write a title<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Please give me some context!  I need to know what the title is about to write a good one. \n",
            "\n",
            "For example, tell me:\n",
            "\n",
            "* **What is the topic of the writing?** (e.g., a short story, a research paper, a blog post)\n",
            "* **What is the main theme or message?** (e.g., love, loss, technology, the environment)\n",
            "* **What is the tone or style?** (e.g., serious, humorous, informative, dramatic)\n",
            "* **Who is the target\n",
            "TOTAL TIME ELAPSED: 6.11s\n",
            "\n",
            "Gemma output:\n",
            "<start_of_turn>user\n",
            "Write a poem<end_of_turn>\n",
            "<start_of_turn>model\n",
            "The wind whispers secrets through rustling leaves,\n",
            "A symphony of gold, the autumn weaves.\n",
            "Sunlight paints the sky in hues of fire,\n",
            "As nature's canvas, burns with desire.\n",
            "\n",
            "A lone crow calls, a mournful, haunting sound,\n",
            "Echoing through the branches, all around.\n",
            "The air grows crisp, a chill upon the breeze,\n",
            "As summer's warmth begins to softly cease.\n",
            "\n",
            "A spider spins its web, a silken thread,\n",
            "A masterpiece of patience, carefully spread.\n",
            "A squirrel scampers, gathering nuts for winter'\n",
            "TOTAL TIME ELAPSED: 6.11s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer designed with multilingual in mind"
      ],
      "metadata": {
        "id": "CEQuiEyBOri8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.GemmaTokenizer.from_preset(model_id)\n",
        "import jax\n",
        "\n",
        "def detoken(tokens):\n",
        "  print(tokens)\n",
        "  for x in tokens:\n",
        "    word = tokenizer.detokenize(jax.numpy.array([x]))\n",
        "    print(f\"{x:6} -> {word}\")\n",
        "\n",
        "detoken(tokenizer(\"안녕하세요. 반갑습니다. 오늘은 날씨가 참 좋네요.\"))"
      ],
      "metadata": {
        "id": "TGE9lYRPOsu8",
        "outputId": "a6748461-e567-4c6e-ce40-20d476221df1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[238179 243415 204551 235265  78821 241772  21743 235265  44245 240703\n",
            " 236648 128856 241215 236361 120816 106509 239156 237526 235265]\n",
            "238179 -> 안\n",
            "243415 -> 녕\n",
            "204551 -> 하세요\n",
            "235265 -> .\n",
            " 78821 ->  반\n",
            "241772 -> 갑\n",
            " 21743 -> 습니다\n",
            "235265 -> .\n",
            " 44245 ->  오\n",
            "240703 -> 늘\n",
            "236648 -> 은\n",
            "128856 ->  날\n",
            "241215 -> 씨\n",
            "236361 -> 가\n",
            "120816 ->  참\n",
            "106509 ->  좋\n",
            "239156 -> 네\n",
            "237526 -> 요\n",
            "235265 -> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ],
      "metadata": {
        "id": "9T7xe_jzslv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.GemmaTokenizer.from_preset(model_id)\n",
        "\n",
        "# example titles\n",
        "data = [\n",
        "    \"푸른 달 아래의 왈츠\",\n",
        "    \"잃어버린 도시의 속삭임\",\n",
        "    \"별빛 아래의 춤\",\n",
        "    \"꿈꾸는 자들의 도시\",\n",
        "    \"시간을 멈추는 시계\",\n",
        "    \"그림자 없는 남자\",\n",
        "    \"붉은 장미의 비밀\",\n",
        "    \"바람이 머무는 곳\",\n",
        "    \"마법의 거울 속으로\",\n",
        "    \"잊혀진 노래의 선율\",\n",
        "    \"밤하늘을 나는 고래\",\n",
        "    \"비밀의 숲 속 오두막\",\n",
        "    \"영혼의 빛\",\n",
        "    \"마지막 잎새의 소원\",\n",
        "    \"꿈꾸는 자들의 낙원\",\n",
        "]\n",
        "\n",
        "train = []\n",
        "\n",
        "for x in data:\n",
        "  item = f\"<start_of_turn>user\\nWrite a title<end_of_turn>\\n<start_of_turn>model\\n{x}<end_of_turn>\"\n",
        "  length = len(tokenizer(item))\n",
        "  # skip data if the token length is longer than our limit\n",
        "  if length < token_limit:\n",
        "    train.append(item)\n",
        "    if(len(train)>=num_data_limit):\n",
        "      break\n",
        "\n",
        "print(len(train))\n",
        "print(train[0])\n",
        "print(train[1])\n",
        "print(train[2])"
      ],
      "metadata": {
        "id": "ZiS-KU9osh_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "203f38dd-2e4f-4642-efdb-c21d4d1673cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n",
            "<start_of_turn>user\n",
            "Write a title<end_of_turn>\n",
            "<start_of_turn>model\n",
            "푸른 달 아래의 왈츠<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Write a title<end_of_turn>\n",
            "<start_of_turn>model\n",
            "잃어버린 도시의 속삭임<end_of_turn>\n",
            "<start_of_turn>user\n",
            "Write a title<end_of_turn>\n",
            "<start_of_turn>model\n",
            "별빛 아래의 춤<end_of_turn>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LoRA Fine-tuning"
      ],
      "metadata": {
        "id": "Pt7Nr6a7tItO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable LoRA for the model and set the LoRA rank to 4.\n",
        "gemma_lm.backbone.enable_lora(rank=lora_rank)\n",
        "gemma_lm.summary()\n",
        "\n",
        "# Limit the input sequence length (to control memory usage).\n",
        "gemma_lm.preprocessor.sequence_length = token_limit\n",
        "# Use AdamW (a common optimizer for transformer models).\n",
        "optimizer = keras.optimizers.AdamW(\n",
        "    learning_rate=lr_value,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "# Exclude layernorm and bias terms from decay.\n",
        "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n",
        "\n",
        "gemma_lm.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=optimizer,\n",
        "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n"
      ],
      "metadata": {
        "id": "RCucu6oHz53G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "3205c58e-3c9b-4824-af82-ba5ffad0688c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n",
              "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
              "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,617,270,528\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,617,270,528\u001b[0m (9.75 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> (9.75 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,928,640\u001b[0m (11.17 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,928,640</span> (11.17 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that enabling LoRA reduces the number of trainable parameters significantly."
      ],
      "metadata": {
        "id": "hQQ47kcdpbZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    #model_name = f\"/content/drive/MyDrive/{lora_name}_{lora_rank}_epoch{epoch+1}.lora.h5\"\n",
        "    #gemma_lm.backbone.save_lora_weights(model_name)\n",
        "\n",
        "    # Evaluate\n",
        "    text_gen(\"Write a title\")\n",
        "    text_gen(\"Write a poem\")\n",
        "\n",
        "history = gemma_lm.fit(train, epochs=train_epoch, batch_size=2, callbacks=[CustomCallback()])\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "26d9npFhAOSp",
        "outputId": "2dca2b5c-25d1-4a6c-c5dc-567f9d4cd318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - loss: 1.4729 - sparse_categorical_accuracy: 0.2734\n",
            "Gemma output:\n",
            "<start_of_turn>user\n",
            "Write a title<end_of_turn>\n",
            "<start_of_turn>model\n",
            "<end_of_turn>\n",
            "TOTAL TIME ELAPSED: 15.49s\n",
            "\n",
            "Gemma output:\n",
            "<start_of_turn>user\n",
            "Write a poem<end_of_turn>\n",
            "<start_of_turn>model\n",
            "The wind whispers secrets through the trees,\n",
            "A rustling symphony, carried on the breeze.\n",
            "Sunlight dances, dappled and bright,\n",
            "Painting shadows in the fading light.\n",
            "\n",
            "A lone bird sings, a melody so clear,\n",
            "A song of hope, dispelling all fear.\n",
            "The world unfolds, a canvas vast,\n",
            "Where dreams take flight, and moments last.\n",
            "\n",
            "The earth breathes deep, a gentle sigh,\n",
            "As clouds drift by, across the sky.\n",
            "A moment caught, in time's embrace,\n",
            "A fleeting beauty, in this sacred space\n",
            "TOTAL TIME ELAPSED: 7.90s\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 12s/step - loss: 1.4512 - sparse_categorical_accuracy: 0.2760\n",
            "Epoch 2/5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - loss: 0.6408 - sparse_categorical_accuracy: 0.5438   \n",
            "Gemma output:\n",
            "<start_of_turn>user\n",
            "Write a title<end_of_turn>\n",
            "<start_of_turn>model\n",
            "<end_of_turn>\n",
            "TOTAL TIME ELAPSED: 0.33s\n",
            "\n",
            "Gemma output:\n",
            "<start_of_turn>user\n",
            "Write a poem<end_of_turn>\n",
            "<start_of_turn>model\n",
            "The wind whispers secrets through the trees,\n",
            "Of ancient tales and forgotten pleas.\n",
            "The sun dips low, a fiery kiss,\n",
            "On fields of gold, a fleeting bliss.\n",
            "The moon ascends, a silver gleam,\n",
            "Casting shadows, a silent dream.\n",
            "The stars ignite, a cosmic dance,\n",
            "A silent song, a fleeting trance.\n",
            "The world sleeps now, beneath the night,\n",
            "A peaceful hush, a gentle light.<end_of_turn>\n",
            "TOTAL TIME ELAPSED: 6.40s\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 4s/step - loss: 0.6337 - sparse_categorical_accuracy: 0.5477\n",
            "Epoch 3/5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810ms/step - loss: 0.3881 - sparse_categorical_accuracy: 0.7470\n",
            "Gemma output:\n",
            "<start_of_turn>user\n",
            "Write a title<end_of_turn>\n",
            "<start_of_turn>model\n",
            "바람의 춤 속 꿈꾸는 소녀<end_of_turn>\n",
            "TOTAL TIME ELAPSED: 1.07s\n",
            "\n",
            "Gemma output:\n",
            "<start_of_turn>user\n",
            "Write a poem<end_of_turn>\n",
            "<start_of_turn>model\n",
            "The wind whispers secrets through the trees,\n",
            "Of ancient lore and forgotten pleas.\n",
            "The moon hangs heavy, a silver tear,\n",
            "Casting shadows, banishing fear.\n",
            "A lone wolf howls, a mournful sound,\n",
            "Echoing through the silent ground.\n",
            "The stars ignite, a diamond dust,\n",
            "As night descends, a velvet trust.\n",
            "The world sleeps deep, a peaceful dream,\n",
            "While shadows dance, a silent gleam.\n",
            "<end_of_turn>model\n",
            "TOTAL TIME ELAPSED: 6.53s\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - loss: 0.3848 - sparse_categorical_accuracy: 0.7472  \n",
            "Epoch 4/5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805ms/step - loss: 0.2722 - sparse_categorical_accuracy: 0.7825\n",
            "Gemma output:\n",
            "<start_of_turn>user\n",
            "Write a title<end_of_turn>\n",
            "<start_of_turn>model\n",
            "꿈꾸는 자들의 낙원<end_of_turn>\n",
            "TOTAL TIME ELAPSED: 0.87s\n",
            "\n",
            "Gemma output:\n",
            "<start_of_turn>user\n",
            "Write a poem<end_of_turn>\n",
            "<start_of_turn>model\n",
            "The moon, a silver coin in the sky,\n",
            "Hangs heavy, watching as the hours fly.\n",
            "A lone owl hoots, a mournful sound,\n",
            "As shadows stretch, and secrets abound.\n",
            "The wind whispers tales of long ago,\n",
            "Of lovers lost, and dreams that glow.\n",
            "The night unfolds, a velvet cloak,\n",
            "Where mysteries and magic evoke.\n",
            "<end_of_turn>\n",
            "TOTAL TIME ELAPSED: 5.48s\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - loss: 0.2710 - sparse_categorical_accuracy: 0.7834  \n",
            "Epoch 5/5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.2029 - sparse_categorical_accuracy: 0.8482   \n",
            "Gemma output:\n",
            "<start_of_turn>user\n",
            "Write a title<end_of_turn>\n",
            "<start_of_turn>model\n",
            "마법의 숲 속 요정<end_of_turn>\n",
            "TOTAL TIME ELAPSED: 0.85s\n",
            "\n",
            "Gemma output:\n",
            "<start_of_turn>user\n",
            "Write a poem<end_of_turn>\n",
            "<start_of_turn>model\n",
            "The moon hangs heavy, a silver tear\n",
            "Upon a canvas of inky night\n",
            "The wind whispers secrets, soft and clear\n",
            "As stars like diamonds pierce the light<end_of_turn>\n",
            "TOTAL TIME ELAPSED: 2.51s\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - loss: 0.2021 - sparse_categorical_accuracy: 0.8487\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load LoRA"
      ],
      "metadata": {
        "id": "P-tVAKmda2Zt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(model_id)\n",
        "# Use the same LoRA rank that you trained\n",
        "#gemma_lm.backbone.enable_lora(rank=4)\n",
        "\n",
        "# Load pre-trained LoRA weights\n",
        "#gemma_lm.backbone.load_lora_weights(f\"/content/drive/MyDrive/{lora_name}_{lora_rank}_epoch{train_epoch}.lora.h5\")"
      ],
      "metadata": {
        "id": "hSW8-HRMa4ZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try a different sampler\n",
        "\n",
        "The top-K algorithm randomly picks the next token from the tokens of top K probability."
      ],
      "metadata": {
        "id": "ipg1u_wEKTxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gemma_lm.compile(sampler=\"top_k\")\n",
        "text_gen(\"Write a title\")\n",
        "text_gen(\"Write a title\")\n",
        "text_gen(\"Write a title\")\n",
        "text_gen(\"Write a title\")\n",
        "text_gen(\"Write a title\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nV5mD_HqKZRF",
        "outputId": "7ff16665-ace7-4c40-d5eb-576bd812e24e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gemma output:\n",
            "<start_of_turn>user\n",
            "Write a title<end_of_turn>\n",
            "<start_of_turn>model\n",
            "바람이 피어나는 밤<end_of_turn>\n",
            "TOTAL TIME ELAPSED: 16.87s\n",
            "\n",
            "Gemma output:\n",
            "<start_of_turn>user\n",
            "Write a title<end_of_turn>\n",
            "<start_of_turn>model\n",
            "꿈꾸는 자들의 낙원<end_of_turn>\n",
            "TOTAL TIME ELAPSED: 0.88s\n",
            "\n",
            "Gemma output:\n",
            "<start_of_turn>user\n",
            "Write a title<end_of_turn>\n",
            "<start_of_turn>model\n",
            "바람은 멈추지 않는다<end_of_turn>\n",
            "TOTAL TIME ELAPSED: 0.95s\n",
            "\n",
            "Gemma output:\n",
            "<start_of_turn>user\n",
            "Write a title<end_of_turn>\n",
            "<start_of_turn>model\n",
            "마법의 숲 속 은빛 요정<end_of_turn>\n",
            "TOTAL TIME ELAPSED: 1.00s\n",
            "\n",
            "Gemma output:\n",
            "<start_of_turn>user\n",
            "Write a title<end_of_turn>\n",
            "<start_of_turn>model\n",
            "바람이 머무는 자리<end_of_turn>\n",
            "TOTAL TIME ELAPSED: 0.87s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try a slight different prompts"
      ],
      "metadata": {
        "id": "3m1XaCrlMu3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_gen(\"Write a music title\")\n",
        "text_gen(\"Write a poem title\")\n",
        "text_gen(\"Write a blog title\")\n",
        "text_gen(\"Write a movie title\")\n",
        "text_gen(\"Write a novel title\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qC-MLxYWM1HU",
        "outputId": "351bcef8-45fc-469c-90c9-edb71cedb9ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gemma output:\n",
            "<start_of_turn>user\n",
            "Write a music title<end_of_turn>\n",
            "<start_of_turn>model\n",
            "비밀스러운 울음소리<end_of_turn>\n",
            "TOTAL TIME ELAPSED: 1.01s\n",
            "\n",
            "Gemma output:\n",
            "<start_of_turn>user\n",
            "Write a poem title<end_of_turn>\n",
            "<start_of_turn>model\n",
            "비밀의 숲 속 요정<end_of_turn>\n",
            "TOTAL TIME ELAPSED: 0.87s\n",
            "\n",
            "Gemma output:\n",
            "<start_of_turn>user\n",
            "Write a blog title<end_of_turn>\n",
            "<start_of_turn>model\n",
            "꿈꾸는 자들의 낙원<end_of_turn>\n",
            "TOTAL TIME ELAPSED: 0.87s\n",
            "\n",
            "Gemma output:\n",
            "<start_of_turn>user\n",
            "Write a movie title<end_of_turn>\n",
            "<start_of_turn>model\n",
            "잊혀진 도시 속의 마법 잃어버린 보물<end_of_turn>\n",
            "TOTAL TIME ELAPSED: 1.35s\n",
            "\n",
            "Gemma output:\n",
            "<start_of_turn>user\n",
            "Write a novel title<end_of_turn>\n",
            "<start_of_turn>model\n",
            "비밀의 숲 속 낙원<end_of_turn>\n",
            "TOTAL TIME ELAPSED: 0.94s\n"
          ]
        }
      ]
    }
  ]
}